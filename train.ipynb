{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eb5f549190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializations\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print('Using ', device)\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "train_set = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())     # Download from open datasets.\n",
    "test_set = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
    "for X, y in train_loader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu3): ReLU()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=288, out_features=128, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Fisrt Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), stride=1, padding=1)      # Convolution Layer: input channel is 1, output channel is 8, kernel size is 3*3, stride is 1, padding is 1\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)                                             # Maxpooling Layer: kernel size is 2*2, stride is 2\n",
    "        self.relu1 = nn.ReLU()                                                                              # Activation Function: ReLU\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Third Convolutional Layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.flatten = nn.Flatten()                                                                         # Flatten the tensor from 3 dimensions to 1 dimension, while keeping the batch size\n",
    "        self.linear1 = nn.Linear(in_features=3*3*32, out_features=128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=128, out_features=10)                                          # Output: 10 categories\n",
    "\n",
    "                                                        # batch_size, channel, height, width\n",
    "    def forward(self, x):                               # torch.Size([1, 1, 28, 28])\n",
    "        x = self.conv1(x)                               # torch.Size([1, 8, 28, 28])\n",
    "        x = self.pool1(x)                               # torch.Size([1, 8, 14, 14])\n",
    "        x = self.relu1(x)                               # torch.Size([1, 8, 14, 14])\n",
    "\n",
    "        x = self.conv2(x)                               # torch.Size([1, 16, 14, 14])\n",
    "        x = self.pool2(x)                               # torch.Size([1, 16, 7, 7])\n",
    "        x = self.relu2(x)                               # torch.Size([1, 16, 7, 7])\n",
    "\n",
    "        x = self.conv3(x)                               # torch.Size([1, 32, 7, 7])\n",
    "        x = self.pool3(x)                               # torch.Size([1, 32, 3, 3])\n",
    "        x = self.relu3(x)                               # torch.Size([1, 32, 3, 3])\n",
    "\n",
    "                                                        # batch_size, features\n",
    "        x = self.flatten(x)                             # torch.Size([1, 288])\n",
    "        x = self.linear1(x)                             # torch.Size([1, 128])\n",
    "        x = self.relu4(x)                               # torch.Size([1, 128])\n",
    "        x = self.linear2(x)                             # torch.Size([1, 10])\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test\n",
    "def train(dataloader, model, loss_fn, optimizer, losses):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_avg = 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward propagation\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "\n",
    "        if batch % 100 == 99:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    losses.append(loss_avg / len(dataloader))\n",
    "\n",
    "def test(dataloader, model, loss_fn, accuracies):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracies.append(correct)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.855362  [ 6400/60000]\n",
      "loss: 0.893030  [12800/60000]\n",
      "loss: 0.739985  [19200/60000]\n",
      "loss: 0.575286  [25600/60000]\n",
      "loss: 0.635278  [32000/60000]\n",
      "loss: 0.577589  [38400/60000]\n",
      "loss: 0.455781  [44800/60000]\n",
      "loss: 0.528937  [51200/60000]\n",
      "loss: 0.479504  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.506244 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.415447  [ 6400/60000]\n",
      "loss: 0.469834  [12800/60000]\n",
      "loss: 0.547069  [19200/60000]\n",
      "loss: 0.517247  [25600/60000]\n",
      "loss: 0.365907  [32000/60000]\n",
      "loss: 0.518078  [38400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     train(train_loader, model, loss_fn, optimizer, losses)\n\u001b[0;32m      7\u001b[0m     test(test_loader, model, loss_fn, accuracies)\n\u001b[0;32m      8\u001b[0m     torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(t) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer, losses)\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m----> 7\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Forward propagation\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "accuracies = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer, losses)\n",
    "    test(test_loader, model, loss_fn, accuracies)\n",
    "    torch.save(model.state_dict(), \"model\\\\model\" + str(t) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "fig, ax1 = plt.subplots()\n",
    "ax = fig.add_subplot(1, 2, 1)               # 1 row, 2 columns, 1st subplot\n",
    "ax.plot(losses)\n",
    "ax.set_title('Training Loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(accuracies)\n",
    "ax.set_title('Test Accuracy')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
